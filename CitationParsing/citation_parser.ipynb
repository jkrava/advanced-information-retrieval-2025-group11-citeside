{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38301503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm \n",
    "import citation_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a txt file with the first N entries of the shard\n",
    "\n",
    "\n",
    "\n",
    "path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\shard1.jsonl\")  # adjust as needed\n",
    "output_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\output_text.txt\")\n",
    "\n",
    "\n",
    "N = 20\n",
    "entries = []\n",
    "\n",
    "with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= N:\n",
    "            break\n",
    "        obj = json.loads(line)\n",
    "        entries.append(obj)\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as out:\n",
    "    for i, obj in enumerate(entries):\n",
    "        out.write(f\"\\n===== ENTRY {i} =====\")\n",
    "        out.write(json.dumps(obj, indent=2, ensure_ascii=False))  # truncate long ones\n",
    "        out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a3ba742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x000002B27AA3BBA0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m output_path.open(\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m citation_parser.iterate_papers(path, N):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         citations = \u001b[43mcitation_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_citations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m         out.write(json.dumps(citations, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m2\u001b[39m))\n\u001b[32m      9\u001b[39m         out.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\CitationParsing\\citation_parser.py:90\u001b[39m, in \u001b[36mget_citations\u001b[39m\u001b[34m(paper)\u001b[39m\n\u001b[32m     87\u001b[39m annotations = body.get(\u001b[33m\"\u001b[39m\u001b[33mannotations\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m annotations = load_annotations_as_lists(annotations, \u001b[33m\"\u001b[39m\u001b[33mbib_ref\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m bibliography_index = \u001b[43mget_bibliography_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m citations: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]= []\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m annotations:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\CitationParsing\\citation_parser.py:56\u001b[39m, in \u001b[36mget_bibliography_index\u001b[39m\u001b[34m(paper)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m bibliography_entries:\n\u001b[32m     55\u001b[39m     attributes = ann.get(\u001b[33m\"\u001b[39m\u001b[33mattributes\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28mid\u001b[39m = \u001b[43mattributes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "#saves the parsed citations from the first N entries of the shard\n",
    "path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\shard1.jsonl\")\n",
    "output_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\citations_shard1_complete.json\")\n",
    "N = 60550\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as out:\n",
    "    for paper in citation_parser.iterate_papers(path, N):\n",
    "        citations = citation_parser.get_citations(paper)\n",
    "        out.write(json.dumps(citations, ensure_ascii=False, indent=2))\n",
    "        out.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b2330c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input papers: 60550\n",
      "Output papers: 49357120\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "input_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\shard1.jsonl\")\n",
    "output_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\citations_shard1_complete.json\")\n",
    "\n",
    "# Count papers in the input shard\n",
    "with input_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    input_papers = sum(1 for line in f if line.strip())\n",
    "print(\"Input papers:\", input_papers)\n",
    "\n",
    "# Count papers in the output (you have one JSON object per paper,\n",
    "# and blank lines between, so count non-empty lines)\n",
    "with output_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    output_papers = sum(1 for line in f if line.strip())\n",
    "print(\"Output papers:\", output_papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37412ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers in output: 59511\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\citations_shard1_complete.json\")\n",
    "\n",
    "with output_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    num_papers_out = sum(1 for line in f if not line.strip())\n",
    "\n",
    "print(\"Papers in output:\", num_papers_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1c75257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in shard: 60550\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "shard_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\shard1.jsonl\")\n",
    "\n",
    "shard_ids = set()\n",
    "with shard_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        paper = json.loads(line)\n",
    "        shard_ids.add(paper[\"corpusid\"])\n",
    "\n",
    "print(\"Number of papers in shard:\", len(shard_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4e7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aac52425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "citations_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\citations_shard1.json\")\n",
    "filtered_path  = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\citations_shard1_intra_shard.jsonl\")  # new JSONL output\n",
    "\n",
    "def iter_parsed_citation_papers(path):\n",
    "    \"\"\"Yield one parsed-citation paper (dict) at a time from citations_shard1.json.\"\"\"\n",
    "    buf = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            # blank line = separator between JSON objects\n",
    "            if not line.strip():\n",
    "                if buf:\n",
    "                    yield json.loads(\"\".join(buf))\n",
    "                    buf = []\n",
    "            else:\n",
    "                buf.append(line)\n",
    "        # last object (if file doesn't end with blank line)\n",
    "        if buf:\n",
    "            yield json.loads(\"\".join(buf))\n",
    "\n",
    "with filtered_path.open(\"w\", encoding=\"utf-8\") as out:\n",
    "    for paper in iter_parsed_citation_papers(citations_path):\n",
    "        paper_id = paper.get(\"paper_id\")\n",
    "\n",
    "        # (Probably redundant, but ensures we only keep papers actually in this shard)\n",
    "        if paper_id not in shard_ids:\n",
    "            continue\n",
    "\n",
    "        citations = paper.get(\"citations\", [])\n",
    "        # keep only citations whose matched_paper_id exists and is also in the shard\n",
    "        filtered_cits = [\n",
    "            c for c in citations\n",
    "            if c.get(\"matched_paper_id\") is not None\n",
    "            and c[\"matched_paper_id\"] in shard_ids\n",
    "        ]\n",
    "\n",
    "        if not filtered_cits:\n",
    "            # no intra-shard citations â†’ drop this paper\n",
    "            continue\n",
    "\n",
    "        paper[\"citations\"] = filtered_cits\n",
    "\n",
    "        # write 1 JSON object per line (much nicer format)\n",
    "        out.write(json.dumps(paper, ensure_ascii=False))\n",
    "        out.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5347d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard papers: 60550\n",
      "Distinct matched_paper_id: 477\n",
      "Number of citations where matched_paper_id is in this shard: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "shard_path     = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\shard1.jsonl\")\n",
    "citations_path = Path(r\"C:\\Users\\User\\Desktop\\Julian\\Uni\\WS 25\\AIR\\herBERT\\Datasets\\Training Data\\s2orc\\shard1\\citations_shard1.json\")  # or your big file\n",
    "\n",
    "# 1) collect all corpusid values from the shard\n",
    "shard_ids = set()\n",
    "with shard_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        paper = json.loads(line)\n",
    "        cid = paper.get(\"corpusid\")\n",
    "        if cid is not None:\n",
    "            shard_ids.add(cid)\n",
    "\n",
    "print(\"Shard papers:\", len(shard_ids))\n",
    "\n",
    "\n",
    "# 2) iterate over your parsed citation objects\n",
    "def iter_parsed_citation_papers(path):\n",
    "    buf = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                if buf:\n",
    "                    yield json.loads(\"\".join(buf))\n",
    "                    buf = []\n",
    "            else:\n",
    "                buf.append(line)\n",
    "        if buf:\n",
    "            yield json.loads(\"\".join(buf))\n",
    "\n",
    "\n",
    "matched_ids = set()\n",
    "intra_shard_count = 0\n",
    "\n",
    "for paper in iter_parsed_citation_papers(citations_path):\n",
    "    for c in paper.get(\"citations\", []):\n",
    "        mid = c.get(\"matched_paper_id\")\n",
    "        if mid is not None:\n",
    "            matched_ids.add(mid)\n",
    "            if mid in shard_ids:\n",
    "                intra_shard_count += 1\n",
    "\n",
    "print(\"Distinct matched_paper_id:\", len(matched_ids))\n",
    "print(\"Number of citations where matched_paper_id is in this shard:\", intra_shard_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
