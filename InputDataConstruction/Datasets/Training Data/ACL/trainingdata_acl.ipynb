{
 "cells": [
  {
   "cell_type": "raw",
   "execution_count": 60,
   "id": "63d41668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"\")\n",
    "GROBID_TAR = DATA_DIR / \"acl_corpus_grobid_full_text.80k.v9_22.tar.gz\"\n",
    "BIB_GZ     = DATA_DIR / \"acl_corpus_bibs.80k.v9_22.tar.gz\"\n",
    "META_PARQUET = DATA_DIR / \"acl-publication-info.74k.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff57e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71641"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "GROBID_TAR = Path(\"acl_corpus_grobid_full_text.80k.v9_22.tar.gz\")\n",
    "\n",
    "tar = tarfile.open(GROBID_TAR, \"r\")\n",
    "members = tar.getmembers()\n",
    "\n",
    "# all .tei.xml files\n",
    "tei_members = [\n",
    "    m for m in members\n",
    "    if m.isfile() and m.name.endswith(\".tei.xml\")\n",
    "]\n",
    "\n",
    "# keep only \"non-trivial\" TEI files, e.g. > 1 KB\n",
    "tei_members_nontrivial = [m for m in tei_members if m.size > 1024]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed428a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     acl_id                                           abstract  \\\n",
       " 0  O02-2002  There is a need to measure word similarity whe...   \n",
       " 1  L02-1310                                                      \n",
       " 2  R13-1042  Thread disentanglement is the task of separati...   \n",
       " 3  W05-0819  In this paper, we describe a word alignment al...   \n",
       " 4  L02-1309                                                      \n",
       " \n",
       "                                            full_text  corpus_paper_id  \\\n",
       " 0  There is a need to measure word similarity whe...         18022704   \n",
       " 1                                                             8220988   \n",
       " 2  Thread disentanglement is the task of separati...         16703040   \n",
       " 3  In this paper, we describe a word alignment al...          1215281   \n",
       " 4                                                            18078432   \n",
       " \n",
       "                                    pdf_hash  numcitedby  \\\n",
       " 0  0b09178ac8d17a92f16140365363d8df88c757d0          14   \n",
       " 1  8d5e31610bc82c2abc86bc20ceba684c97e66024          93   \n",
       " 2  3eb736b17a5acb583b9a9bd99837427753632cdb          10   \n",
       " 3  b20450f67116e59d1348fc472cfc09f96e348f55          15   \n",
       " 4  011e943b64a78dadc3440674419821ee080f0de3          12   \n",
       " \n",
       "                                                  url  \\\n",
       " 0                  https://aclanthology.org/O02-2002   \n",
       " 1  http://www.lrec-conf.org/proceedings/lrec2002/...   \n",
       " 2                  https://aclanthology.org/R13-1042   \n",
       " 3                  https://aclanthology.org/W05-0819   \n",
       " 4  http://www.lrec-conf.org/proceedings/lrec2002/...   \n",
       " \n",
       "                                         publisher  \\\n",
       " 0                                            None   \n",
       " 1  European Language Resources Association (ELRA)   \n",
       " 2                   INCOMA Ltd. Shoumen, BULGARIA   \n",
       " 3       Association for Computational Linguistics   \n",
       " 4  European Language Resources Association (ELRA)   \n",
       " \n",
       "                               address  year  ...  \\\n",
       " 0                                None  2002  ...   \n",
       " 1  Las Palmas, Canary Islands - Spain  2002  ...   \n",
       " 2                    Hissar, Bulgaria  2013  ...   \n",
       " 3                 Ann Arbor, Michigan  2005  ...   \n",
       " 4  Las Palmas, Canary Islands - Spain  2002  ...   \n",
       " \n",
       "                                            booktitle  \\\n",
       " 0  International Journal of Computational Linguis...   \n",
       " 1  Proceedings of the Third International Confere...   \n",
       " 2  Proceedings of the International Conference Re...   \n",
       " 3  Proceedings of the {ACL} Workshop on Building ...   \n",
       " 4  Proceedings of the Third International Confere...   \n",
       " \n",
       "                                               author  \\\n",
       " 0                Chen, Keh-Jiann  and\\nYou, Jia-Ming   \n",
       " 1                                  Mihalcea, Rada F.   \n",
       " 2               Jamison, Emily  and\\nGurevych, Iryna   \n",
       " 3             Aswani, Niraj  and\\nGaizauskas, Robert   \n",
       " 4  Suyaga, Fumiaki  and\\nTakezawa, Toshiyuki  and...   \n",
       " \n",
       "                                                title     pages   doi number  \\\n",
       " 0  A Study on Word Similarity using Context Vecto...    37--58  None   None   \n",
       " 1           Bootstrapping Large Sense Tagged Corpora      None  None   None   \n",
       " 2  Headerless, Quoteless, but not Hopeless? Using...  327--335  None   None   \n",
       " 3  Aligning Words in {E}nglish-{H}indi Parallel C...  115--118  None   None   \n",
       " 4  Proposal of a very-large-corpus acquisition me...      None  None   None   \n",
       " \n",
       "   volume journal editor  isbn  \n",
       " 0   None    None   None  None  \n",
       " 1   None    None   None  None  \n",
       " 2   None    None   None  None  \n",
       " 3   None    None   None  None  \n",
       " 4   None    None   None  None  \n",
       " \n",
       " [5 rows x 21 columns],\n",
       " Index(['acl_id', 'abstract', 'full_text', 'corpus_paper_id', 'pdf_hash',\n",
       "        'numcitedby', 'url', 'publisher', 'address', 'year', 'month',\n",
       "        'booktitle', 'author', 'title', 'pages', 'doi', 'number', 'volume',\n",
       "        'journal', 'editor', 'isbn'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_parquet(META_PARQUET) \n",
    "meta.head(), meta.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f1e91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outgoing = defaultdict(list)\n",
    "incoming = defaultdict(list)\n",
    "\n",
    "for u, v in edges:\n",
    "    outgoing[u].append(v)\n",
    "    incoming[v].append(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f76f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9319"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acl_meta_ids = set(meta_acl[\"acl_id\"].tolist())\n",
    "\n",
    "linked_ids = [\n",
    "    pid for pid in acl_meta_ids\n",
    "    if pid in outgoing and outgoing[pid]\n",
    "]\n",
    "\n",
    "len(linked_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bdbb3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "small_linked_ids = random.sample(linked_ids, min(800, len(linked_ids)))\n",
    "len(small_linked_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c9821fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_acl_by_id = {\n",
    "    row[\"acl_id\"]: row.to_dict()\n",
    "    for _, row in meta_acl.iterrows()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81f04cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,\n",
       " '2020.wmt-1.91',\n",
       " ['D16-1160', 'P16-1009', 'P19-1021', 'W17-4714', 'W18-2703'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_records = []\n",
    "\n",
    "for pid in small_linked_ids:\n",
    "    m = meta_acl_by_id[pid]\n",
    "\n",
    "    record = {\n",
    "        \"paper_id\": pid,\n",
    "        \"title\": m.get(\"title\"),\n",
    "        \"abstract\": m.get(\"abstract\"),\n",
    "        \"full_text\": m.get(\"full_text\"),\n",
    "        \"year\": m.get(\"year\"),\n",
    "        \"month\": m.get(\"month\"),\n",
    "        \"booktitle\": m.get(\"booktitle\"),\n",
    "        \"authors\": m.get(\"author\"),  # may be a string or list depending on how it's stored\n",
    "        \"venue\": m.get(\"journal\") or m.get(\"booktitle\"),\n",
    "        \"doi\": m.get(\"doi\"),\n",
    "        \"numcitedby_s2\": m.get(\"numcitedby\"),\n",
    "        \"s2_id\": m.get(\"corpus_paper_id\"),\n",
    "        \"url\": m.get(\"url\"),\n",
    "        \"publisher\": m.get(\"publisher\"),\n",
    "        \"address\": m.get(\"address\"),\n",
    "        # graph-level info\n",
    "        \"outgoing_acl_citations\": sorted(set(outgoing.get(pid, []))),\n",
    "        \"incoming_acl_citations\": sorted(set(incoming.get(pid, []))),\n",
    "    }\n",
    "\n",
    "    final_records.append(record)\n",
    "\n",
    "len(final_records), final_records[0][\"paper_id\"], final_records[0][\"outgoing_acl_citations\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b166b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"acl_small_fulltext_linked.parquet_based.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_records, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb289e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# point this to the directory that contains the ReferenceTreeTools folder\n",
    "PROJECT_ROOT = Path(\"C:\\\\Users\\\\User\\\\Desktop\\\\Julian\\\\Uni\\\\WS 25\\\\AIR\\\\herBERT\").resolve()\n",
    "\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "\n",
    "def build_acl_citation_edges(ids):\n",
    "    edges = []\n",
    "    for pid in ids:\n",
    "        tei_member = tei_by_id[pid]\n",
    "        with tar.extractfile(tei_member) as f:\n",
    "            xml_bytes = f.read()\n",
    "        try:\n",
    "            refs = extract_refs_from_tei_with_acl(xml_bytes)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        for r in refs:\n",
    "            cid = r.get(\"acl_id\")\n",
    "            if cid and cid in tei_by_id:\n",
    "                edges.append((pid, cid))\n",
    "    return edges\n",
    "\n",
    "edges = build_acl_citation_edges(common_ids)\n",
    "len(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e6ad490",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m     16\u001B[39m                 edges.append((pid, cid))\n\u001B[32m     17\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m edges\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m edges = \u001B[43mbuild_acl_citation_edges\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommon_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[38;5;28mlen\u001B[39m(edges)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 8\u001B[39m, in \u001B[36mbuild_acl_citation_edges\u001B[39m\u001B[34m(ids)\u001B[39m\n\u001B[32m      6\u001B[39m tei_member = tei_by_id[pid]\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m tar.extractfile(tei_member) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     xml_bytes = \u001B[43mf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     10\u001B[39m     refs = extract_refs_from_tei_with_acl(xml_bytes)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tarfile.py:691\u001B[39m, in \u001B[36m_FileInFile.read\u001B[39m\u001B[34m(self, size)\u001B[39m\n\u001B[32m    689\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[32m    690\u001B[39m     \u001B[38;5;28mself\u001B[39m.fileobj.seek(offset + (\u001B[38;5;28mself\u001B[39m.position - start))\n\u001B[32m--> \u001B[39m\u001B[32m691\u001B[39m     b = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfileobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    692\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(b) != length:\n\u001B[32m    693\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m ReadError(\u001B[33m\"\u001B[39m\u001B[33munexpected end of data\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1) Pick a random root node that has outgoing citations\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "candidate_nodes = [pid for pid, vs in outgoing.items() if len(vs) > 0]\n",
    "root = random.choice(candidate_nodes)\n",
    "print(\"Random root:\", root)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) Build a tiny citation neighborhood (BFS)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "MAX_DEPTH = 10\n",
    "REVERSE_DEPTH = 10\n",
    "\n",
    "# Build incoming edges if not defined\n",
    "incoming = {}\n",
    "for u, vs in outgoing.items():\n",
    "    for v in vs:\n",
    "        incoming.setdefault(v, []).append(u)\n",
    "\n",
    "visited = set([root])\n",
    "queue = deque([(root, 0)])\n",
    "\n",
    "# --- Forward BFS: papers ROOT cites ---\n",
    "while queue:\n",
    "    pid, depth = queue.popleft()\n",
    "    if depth >= MAX_DEPTH:\n",
    "        continue\n",
    "    for neigh in outgoing.get(pid, []):\n",
    "        if neigh not in visited:\n",
    "            visited.add(neigh)\n",
    "            queue.append((neigh, depth + 1))\n",
    "\n",
    "# --- Reverse BFS: papers that cite ROOT ---\n",
    "queue = deque([(root, 0)])\n",
    "while queue:\n",
    "    pid, depth = queue.popleft()\n",
    "    if depth >= REVERSE_DEPTH:\n",
    "        continue\n",
    "    for neigh in incoming.get(pid, []):\n",
    "        if neigh not in visited:\n",
    "            visited.add(neigh)\n",
    "            queue.append((neigh, depth + 1))\n",
    "\n",
    "print(\"Visited nodes:\", len(visited))\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Filter edges within this tiny subgraph\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "mini_edges = [(u, v) for (u, v) in edges if u in visited and v in visited]\n",
    "print(\"Edges in small subgraph:\", len(mini_edges))\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) Build reference tree\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "from herBERT.ReferenceTreeTools.ReferenceTreeBuilder import ReferenceTreeBuilder\n",
    "\n",
    "rtb = ReferenceTreeBuilder()\n",
    "\n",
    "# Add nodes\n",
    "for pid in visited:\n",
    "    rtb.addNode(pid)\n",
    "\n",
    "# Add edges\n",
    "for u, v in mini_edges:\n",
    "    rtb.addEdge(u, v)\n",
    "\n",
    "# Build internal structure\n",
    "rtb.build()\n",
    "\n",
    "# Store + reload (required for printTree / plotTree)\n",
    "out_dir = os.path.join(os.getcwd(), \"output\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "out_path = os.path.join(out_dir, f\"rtb_tree_{root}.json\")\n",
    "rtb.store(out_path)\n",
    "\n",
    "tree = rtb.load(out_path)\n",
    "\n",
    "print(\"Stored tree:\", out_path)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) Print + Plot\n",
    "# ---------------------------------------------------------------------\n",
    "tree.printTree()\n",
    "tree.plotTree()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
